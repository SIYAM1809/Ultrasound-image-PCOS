{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12819776,"sourceType":"datasetVersion","datasetId":8106764},{"sourceId":257762941,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob, os\nprint(\"Mounted pcosgen_out paths:\", glob.glob(\"/kaggle/input/*/pcosgen_out\"))\nprint(\"All inputs under /kaggle/input:\", os.listdir(\"/kaggle/input\"))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-24T06:53:31.625431Z","iopub.execute_input":"2025-08-24T06:53:31.625969Z","iopub.status.idle":"2025-08-24T06:53:31.638842Z","shell.execute_reply.started":"2025-08-24T06:53:31.625946Z","shell.execute_reply":"2025-08-24T06:53:31.638092Z"}},"outputs":[{"name":"stdout","text":"Mounted pcosgen_out paths: ['/kaggle/input/pcos-pic/pcosgen_out']\nAll inputs under /kaggle/input: ['pcos-pic', 'pcos-picture']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# === Cell A: Environment locks & imports ===\n!pip -q uninstall -y albumentations albucore\n!pip -q install --no-deps albucore==0.0.20 albumentations==1.4.16 timm==0.9.16\n\nimport os, glob, json, math, warnings, time, hashlib\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn.metrics import (\n    roc_auc_score, f1_score, accuracy_score, confusion_matrix,\n    roc_curve, auc, precision_recall_curve, ConfusionMatrixDisplay\n)\n\nimport timm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T06:54:00.175838Z","iopub.execute_input":"2025-08-24T06:54:00.176100Z","iopub.status.idle":"2025-08-24T06:54:17.271081Z","shell.execute_reply.started":"2025-08-24T06:54:00.176081Z","shell.execute_reply":"2025-08-24T06:54:17.270296Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.6/214.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# === Cell B: Config, copy artifacts, rebuild df ===\nclass CFG:\n    BASE = \"/kaggle/input/pcos-picture\"  # dataset with images & labels\n    OUT_DIR = \"/kaggle/working/pcosgen_out\"\n    img_size = 448\n    batch_size = 24\n    num_workers = 4\n    backbone = \"convnext_tiny.fb_in22k\"\n\n# --- copy previous outputs (pcosgen_out) from your prior Version input ---\ncand = glob.glob(\"/kaggle/input/*/pcosgen_out\")\nassert len(cand) > 0, \"Could not find previous pcosgen_out under /kaggle/input/*/pcosgen_out. Add your prior version as an Input.\"\nSRC_OUT = cand[0]\n!rm -rf /kaggle/working/pcosgen_out\n!cp -r \"$SRC_OUT\" /kaggle/working/pcosgen_out\nprint(\"Restored artifacts from:\", SRC_OUT)\n\n# --- rebuild df from pcos-picture ---\ndef load_labels_from_table(path):\n    ext = os.path.splitext(path)[1].lower()\n    df_lab = pd.read_excel(path, sheet_name=0) if ext in [\".xlsx\", \".xls\"] else pd.read_csv(path)\n    df_lab.columns = [str(c).strip().lower() for c in df_lab.columns]\n    img_col = next((c for c in [\"imagepath\",\"image\",\"filename\",\"file\",\"img\",\"name\"] if c in df_lab.columns), None)\n    lab_col = next((c for c in [\"healthy\",\"label\",\"class\",\"target\",\"y\"] if c in df_lab.columns), None)\n    assert img_col and lab_col, \"Image or Label column not found.\"\n    name = (df_lab[img_col].astype(str).str.strip().apply(os.path.basename).str.lower())\n    lab = (df_lab[lab_col].astype(str).str.strip().str.lower()\n           .map({\"1\":1,\"0\":0,\"healthy\":1,\"unhealthy\":0,\"h\":1,\"u\":0}).astype(int))\n    table = pd.DataFrame({\"image\": name, \"label\": lab}).dropna().drop_duplicates(\"image\", keep=\"last\")\n    return dict(zip(table[\"image\"], table[\"label\"]))\n\ndef list_images(dir_path):\n    exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n    return sorted([str(p) for p in Path(dir_path).glob(\"*\") if str(p).lower().endswith(exts)])\n\ntrain_path = Path(CFG.BASE) / \"PCOSGen-train (1)\" / \"PCOSGen-train\"\nTRAIN_DIR = str(train_path / \"images\")\nLABELS_FILE = str(train_path / \"class_label.xlsx\")\n\ntrain_files = list_images(TRAIN_DIR)\nbn_to_path = {os.path.basename(p).lower(): p for p in train_files}\nlabel_map = load_labels_from_table(LABELS_FILE)\ndf = pd.DataFrame([(bn_to_path[bn], lab) for bn, lab in label_map.items() if bn in bn_to_path],\n                  columns=[\"path\",\"y\"]).reset_index(drop=True)\nprint(\"Train images in df:\", len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T06:54:41.105346Z","iopub.execute_input":"2025-08-24T06:54:41.106179Z","iopub.status.idle":"2025-08-24T06:54:48.459678Z","shell.execute_reply.started":"2025-08-24T06:54:41.106150Z","shell.execute_reply":"2025-08-24T06:54:48.458887Z"}},"outputs":[{"name":"stdout","text":"Restored artifacts from: /kaggle/input/pcos-pic/pcosgen_out\nTrain images in df: 3200\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# === Cell C: Transforms, dataset, model helpers ===\nIMAGENET_MEAN, IMAGENET_STD = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n\nvalid_tfms = A.Compose([\n    A.LongestMaxSize(max_size=CFG.img_size),\n    A.PadIfNeeded(CFG.img_size, CFG.img_size, border_mode=cv2.BORDER_REFLECT),\n    A.CLAHE(p=1.0),\n    A.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n    ToTensorV2(),\n])\n\nclass USDataset(Dataset):\n    def __init__(self, df, transform):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n    def __len__(self): return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = cv2.imread(row.path, cv2.IMREAD_UNCHANGED)\n        if img is None:\n            img = np.zeros((CFG.img_size, CFG.img_size), dtype=np.uint8)\n        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.ndim == 2 else cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        x = self.transform(image=img)[\"image\"]\n        y = int(row.y)\n        return x, torch.tensor([y], dtype=torch.float32)\n\ndef compute_metrics(y_true, y_prob, thr=0.5):\n    y_true = np.asarray(y_true).astype(int)\n    y_pred = (y_prob >= thr).astype(int)\n    auc_v = roc_auc_score(y_true, y_prob) if len(np.unique(y_true))>1 else 0.5\n    f1 = f1_score(y_true, y_pred)\n    acc = accuracy_score(y_true, y_pred)\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n    spec = tn / (tn+fp+1e-9)\n    rec  = tp / (tp+fn+1e-9)\n    return dict(AUC=auc_v, F1=f1, ACC=acc, SPEC_unhealthy=spec, RECALL_healthy=rec)\n\ndef best_threshold(y_true, y_prob, metric=\"J\", n=1001):\n    thrs = np.linspace(0.0, 1.0, n)\n    best_t, best_v = 0.5, -1.0\n    for t in thrs:\n        m = compute_metrics(y_true, y_prob, thr=t)\n        v = m[\"RECALL_healthy\"] + m[\"SPEC_unhealthy\"] - 1.0  # Youden's J\n        if v > best_v:\n            best_v, best_t = v, t\n    return float(best_t), float(best_v)\n\ndef find_threshold_for_spec(y_true, y_prob, target_spec=0.80):\n    for t in np.linspace(0, 1, 1001):\n        if compute_metrics(y_true, y_prob, thr=t)['SPEC_unhealthy'] >= target_spec:\n            return float(t)\n    return 0.5\n\nclass PCOSNet(nn.Module):\n    def __init__(self, backbone=CFG.backbone, pretrained=False):\n        super().__init__()\n        self.backbone = timm.create_model(backbone, pretrained=pretrained, num_classes=1, in_chans=3, drop_rate=0.2)\n    def forward(self, x): return self.backbone(x).squeeze(1)\n\ndef load_ckpt_into_base(ckpt, backbone, device):\n    model = PCOSNet(backbone, pretrained=False).to(device)\n    sd = ckpt[\"state_dict\"]\n    if any(k.startswith(\"module.\") for k in sd.keys()):\n        sd = {k.replace(\"module.\", \"\", 1): v for k, v in sd.items()}\n    model.load_state_dict(sd, strict=True)\n    model.eval()\n    return model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n@torch.no_grad()\ndef tta_logits(model, xb, do_transpose=True):\n    outs = []\n    outs.append(model(xb))\n    outs.append(model(torch.flip(xb, dims=[-1])))\n    outs.append(model(torch.flip(xb, dims=[-2])))\n    outs.append(model(torch.flip(torch.flip(xb, [-1]), [-2])))\n    if do_transpose:\n        xbt = xb.transpose(-1, -2).contiguous()\n        outs.append(model(xbt))\n        outs.append(model(torch.flip(xbt, dims=[-1])))\n        outs.append(model(torch.flip(xbt, dims=[-2])))\n        outs.append(model(torch.flip(torch.flip(xbt, [-1]), [-2])))\n    return sum(outs) / len(outs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T06:55:33.526759Z","iopub.execute_input":"2025-08-24T06:55:33.527217Z","iopub.status.idle":"2025-08-24T06:55:33.641782Z","shell.execute_reply.started":"2025-08-24T06:55:33.527190Z","shell.execute_reply":"2025-08-24T06:55:33.641010Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# === Cell R1: restore thresholds from previous run ===\nwith open(f\"{CFG.OUT_DIR}/thresholds.json\") as f:\n    THR = json.load(f)\n\nglobal_t_temp = float(THR[\"global_t_temp\"])\nthr_j  = float(THR[\"thr_j\"])\nthr_s80= float(THR[\"thr_s80\"])\nthr_85 = float(THR[\"thr_85\"])\nprint(\"Restored thresholds:\", {k: THR[k] for k in [\"global_t_temp\",\"thr_j\",\"thr_s80\",\"thr_85\"]})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T06:55:47.332263Z","iopub.execute_input":"2025-08-24T06:55:47.332894Z","iopub.status.idle":"2025-08-24T06:55:47.338890Z","shell.execute_reply.started":"2025-08-24T06:55:47.332868Z","shell.execute_reply":"2025-08-24T06:55:47.338202Z"}},"outputs":[{"name":"stdout","text":"Restored thresholds: {'global_t_temp': 0.581762619911359, 'thr_j': 0.463, 'thr_s80': 0.483, 'thr_85': 0.46346965432167053}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# === Cell 17R-FAST: Accurate latency (model-only + optional preprocessing) ===\nimport os, glob, time, json, math, numpy as np\nimport torch, torch.nn as nn\n\n# ---- safe fallbacks ----\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nOUT = getattr(CFG, \"OUT_DIR\", \"/kaggle/working/pcosgen_out\")\nIMG = getattr(CFG, \"img_size\", 448)\nUSE_TTA = False   # fair vs tabular; set True if you also want TTA timing\nBATCHES = [1, 8, 32]  # report online latency (1) and throughput (8, 32)\nWARMUP = 20\nITERS  = 100      # increase to 200+ for even tighter error bars\n\n# ---- helpers ----\ndef _forward(model, xb, use_tta=False):\n    if use_tta and \"tta_logits\" in globals():\n        return tta_logits(model, xb)\n    return model(xb)\n\n@torch.no_grad()\ndef time_one_setting(model, bs, iters=ITERS, warmup=WARMUP, use_tta=False):\n    model.eval()\n    x = torch.randn(bs, 3, IMG, IMG, device=device)\n\n    use_amp = (device.type == \"cuda\")\n    # warmup\n    for _ in range(warmup):\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            _ = _forward(model, x, use_tta)\n        if device.type == \"cuda\":\n            torch.cuda.synchronize()\n\n    # timing (CUDA events for precision)\n    if device.type == \"cuda\":\n        starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n        times = []\n        for _ in range(iters):\n            starter.record()\n            with torch.cuda.amp.autocast(enabled=use_amp):\n                _ = _forward(model, x, use_tta)\n            ender.record()\n            torch.cuda.synchronize()\n            times.append(starter.elapsed_time(ender) / 1000.0)  # seconds\n    else:\n        times = []\n        for _ in range(iters):\n            t0 = time.perf_counter()\n            _ = _forward(model, x, use_tta)\n            t1 = time.perf_counter()\n            times.append(t1 - t0)\n\n    times = np.array(times, dtype=float)\n    per_img_ms = times.mean() * 1000.0 / bs\n    result = {\n        \"batch_size\": int(bs),\n        \"mean_s\": float(times.mean()),\n        \"median_s\": float(np.median(times)),\n        \"p90_s\": float(np.percentile(times, 90)),\n        \"p99_s\": float(np.percentile(times, 99)),\n        \"per_image_ms\": float(per_img_ms),\n        \"throughput_img_per_s\": float(bs / times.mean())\n    }\n    return result\n\n# ---- load best checkpoint by stored AUC ----\ncands = sorted(glob.glob(f\"{OUT}/model_fold*.pt\"))\nassert len(cands) > 0, \"No checkpoints found in OUT_DIR.\"\nbest_auc, best_p = -1.0, None\nfor p in cands:\n    meta = torch.load(p, map_location=\"cpu\", weights_only=False)\n    a = float(meta.get(\"auc\", -1.0))\n    if a > best_auc: best_auc, best_p = a, p\n\nckpt = torch.load(best_p, map_location=device, weights_only=False)\nmodel = load_ckpt_into_base(ckpt, ckpt[\"backbone\"], device)\n# Optional: use both GPUs for max throughput\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)\nprint(f\"[latency] Using {os.path.basename(best_p)} (AUC meta={best_auc:.4f}) on {device}\")\n\n# ---- run timings (no-TTA and optionally TTA) ----\nsummary = {\"device\": str(device), \"img_size\": int(IMG), \"tta\": bool(USE_TTA), \"results\": []}\nfor bs in BATCHES:\n    res_no = time_one_setting(model, bs, use_tta=False)\n    entry = {\"mode\": f\"no_TTA_bs{bs}\", **res_no}\n    summary[\"results\"].append(entry)\n    print(entry)\n\nif USE_TTA:\n    for bs in BATCHES:\n        res_tta = time_one_setting(model, bs, use_tta=True)\n        entry = {\"mode\": f\"TTA_bs{bs}\", **res_tta}\n        summary[\"results\"].append(entry)\n        print(entry)\n\n# ---- optional: preprocessing (Albumentations valid_tfms) timing on a small sample ----\ntry:\n    import cv2, random\n    import albumentations as A\n    from albumentations.pytorch import ToTensorV2\n    assert \"valid_tfms\" in globals() and \"df\" in globals() and len(df) > 0\n    n = min(200, len(df))  # small, just to estimate CPU preprocessing cost\n    paths = df.sample(n=n, random_state=123).path.tolist()\n    t0 = time.perf_counter()\n    for p in paths:\n        img = cv2.imread(p, cv2.IMREAD_UNCHANGED)\n        if img is None: continue\n        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) if img.ndim == 2 else cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        _ = valid_tfms(image=img)[\"image\"]  # tensor (unused)\n    t1 = time.perf_counter()\n    prep_ms_per_img = (t1 - t0) * 1000.0 / max(1, n)\n    summary[\"preprocessing_ms_per_image_CPU\"] = float(prep_ms_per_img)\n    print({\"preprocessing_ms_per_image_CPU\": prep_ms_per_img})\nexcept Exception as e:\n    print(f\"[prep] skipped preprocessing timing: {e}\")\n\n# ---- save\nos.makedirs(OUT, exist_ok=True)\nwith open(f\"{OUT}/latency_report_fast.json\", \"w\") as f:\n    json.dump(summary, f, indent=2)\nprint(f\"[latency] Saved -> {OUT}/latency_report_fast.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T09:40:34.398908Z","iopub.execute_input":"2025-08-24T09:40:34.399667Z","iopub.status.idle":"2025-08-24T09:41:13.113926Z","shell.execute_reply.started":"2025-08-24T09:40:34.399640Z","shell.execute_reply":"2025-08-24T09:41:13.113274Z"}},"outputs":[{"name":"stdout","text":"[latency] Using model_fold1.pt (AUC meta=0.8574) on cuda\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3227563125.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=use_amp):\n/tmp/ipykernel_36/3227563125.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=use_amp):\n","output_type":"stream"},{"name":"stdout","text":"{'mode': 'no_TTA_bs1', 'batch_size': 1, 'mean_s': 0.03196150320053101, 'median_s': 0.028668736457824705, 'p90_s': 0.030194438362121583, 'p99_s': 0.0344940617370621, 'per_image_ms': 31.96150320053101, 'throughput_img_per_s': 31.28763981236608}\n{'mode': 'no_TTA_bs8', 'batch_size': 8, 'mean_s': 0.06587895389556886, 'median_s': 0.06557700729370117, 'p90_s': 0.06621220245361328, 'p99_s': 0.07705201400756839, 'per_image_ms': 8.234869236946107, 'throughput_img_per_s': 121.4348365743873}\n{'mode': 'no_TTA_bs32', 'batch_size': 32, 'mean_s': 0.1911335923767089, 'median_s': 0.1894207992553711, 'p90_s': 0.19182490692138673, 'p99_s': 0.1954764141845714, 'per_image_ms': 5.972924761772154, 'throughput_img_per_s': 167.42216583744514}\n{'preprocessing_ms_per_image_CPU': 7.469219194999823}\n[latency] Saved -> /kaggle/working/pcosgen_out/latency_report_fast.json\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import json, pprint, os\np = \"/kaggle/working/pcosgen_out/latency_report_fast.json\"\nwith open(p) as f: rpt = json.load(f)\n\n# pull the rows you need\nr1  = [r for r in rpt[\"results\"] if r[\"mode\"]==\"no_TTA_bs1\"][0]\nr8  = [r for r in rpt[\"results\"] if r[\"mode\"]==\"no_TTA_bs8\"][0]\nr32 = [r for r in rpt[\"results\"] if r[\"mode\"]==\"no_TTA_bs32\"][0]\nprep = rpt.get(\"preprocessing_ms_per_image_CPU\", None)\n\nprint(f\"ms/img (no-TTA, bs=1): {r1['per_image_ms']:.2f} ms\")\nprint(f\"imgs/s (no-TTA, bs=8): {r8['throughput_img_per_s']:.2f} img/s\")\nprint(f\"imgs/s (no-TTA, bs=32): {r32['throughput_img_per_s']:.2f} img/s\")\nif prep is not None:\n    print(f\"End-to-end (bs=1, approx): {r1['per_image_ms']+prep:.2f} ms/img\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T09:58:17.353745Z","iopub.execute_input":"2025-08-24T09:58:17.354358Z","iopub.status.idle":"2025-08-24T09:58:17.360752Z","shell.execute_reply.started":"2025-08-24T09:58:17.354333Z","shell.execute_reply":"2025-08-24T09:58:17.360109Z"}},"outputs":[{"name":"stdout","text":"ms/img (no-TTA, bs=1): 31.96 ms\nimgs/s (no-TTA, bs=8): 121.43 img/s\nimgs/s (no-TTA, bs=32): 167.42 img/s\nEnd-to-end (bs=1, approx): 39.43 ms/img\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# === Cell 19R2: Build HTML appendix from saved files ===\nimport base64\nfrom datetime import datetime\n\ndef _img_data_uri(p):\n    try:\n        with open(p, 'rb') as f: return 'data:image/png;base64,' + base64.b64encode(f.read()).decode('ascii')\n    except Exception: return None\n\ndef build_html_appendix_fileonly(out_html=f\"{CFG.OUT_DIR}/appendix.html\"):\n    def try_json(p):\n        try:\n            with open(p) as f: return json.load(f)\n        except Exception: return {}\n\n    thr = try_json(f\"{CFG.OUT_DIR}/thresholds.json\")\n    rep = try_json(f\"{CFG.OUT_DIR}/latency_report.json\")\n    metrics_ci = try_json(f\"{CFG.OUT_DIR}/oof_metrics_ci.json\")\n\n    imgs = {\n        'ROC Curve': f\"{CFG.OUT_DIR}/oof_roc.png\",\n        'PR Curve': f\"{CFG.OUT_DIR}/oof_pr.png\",\n        'Reliability': f\"{CFG.OUT_DIR}/oof_reliability.png\",\n        'DET Curve': f\"{CFG.OUT_DIR}/oof_det.png\",\n        'Score Histogram': f\"{CFG.OUT_DIR}/oof_score_hist.png\",\n        'Class Balance': f\"{CFG.OUT_DIR}/class_balance.png\",\n        'Augmentations': f\"{CFG.OUT_DIR}/aug_preview_grid.png\",\n        'CM @ J*': f\"{CFG.OUT_DIR}/cm_J_star.png\",\n        'CM @ Spec80': f\"{CFG.OUT_DIR}/cm_spec80.png\",\n        'Robustness Δ': f\"{CFG.OUT_DIR}/robustness_deltas.png\",\n        'Decision Curve': f\"{CFG.OUT_DIR}/decision_curve.png\",\n    }\n    gradcams = sorted(glob.glob(f\"{CFG.OUT_DIR}/gradcam/*.png\"))[:24]\n\n    styles = \"<style>body{font-family:system-ui,sans-serif;margin:2rem}h1,h2{margin-bottom:0.5rem}.grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(300px,1fr));gap:1rem}.card{border:1px solid #ddd;border-radius:8px;padding:1rem;box-shadow:0 2px 4px #0001}table{border-collapse:collapse;width:100%;margin-top:1rem}th,td{border:1px solid #ddd;padding:8px;text-align:left}th{background:#f7f7f7}</style>\"\n    kpis = []\n    for k in [\"thr_j\",\"thr_s80\",\"thr_85\",\"global_t_temp\"]:\n        if k in thr: kpis.append(f\"<div class='card'><b>{k}</b><br>{thr[k]:.4f}</div>\")\n    kpi_html = \"\".join(kpis)\n\n    lat_html = \"\"\n    if rep:\n        lat_html = f\"<table><tr><th>Mode</th><th>Mean (ms/img)</th><th>Throughput (img/s)</th></tr>\" \\\n                   f\"<tr><td>No-TTA</td><td>{rep['per_img_ms_no_tta']['mean']:.2f}</td><td>{rep['throughput_imgs_per_sec_no_tta']:.1f}</td></tr>\" \\\n                   f\"<tr><td>TTA</td><td>{rep['per_img_ms_tta']['mean']:.2f}</td><td>{rep['throughput_imgs_per_sec_tta']:.1f}</td></tr></table>\"\n\n    plots_html = \"\".join([f\"<div class='card'><h3>{k}</h3><img src='{_img_data_uri(v)}' style='width:100%'></div>\"\n                          for k,v in imgs.items() if os.path.exists(v)])\n    gradcam_html = \"\".join([f\"<div class='card'><b>{os.path.basename(p)}</b><img src='{_img_data_uri(p)}' style='width:100%'></div>\"\n                            for p in gradcams])\n\n    ci_html = \"\"\n    if metrics_ci:\n        rows = \"\".join([f\"<tr><td>{k}</td><td>{v['mean']:.3f}</td><td>[{v['ci95'][0]:.3f}, {v['ci95'][1]:.3f}]</td></tr>\" for k,v in metrics_ci.items()])\n        ci_html = f\"<h2>OOF 95% CIs</h2><table><tr><th>Metric</th><th>Mean</th><th>95% CI</th></tr>{rows}</table>\"\n\n    html = f\"<!DOCTYPE html><html><head>{styles}<title>PCOS Appendix</title></head><body>\"\n    html += f\"<h1>PCOS Appendix</h1><p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\"\n    if kpi_html: html += f\"<h2>Key thresholds</h2><div class='grid'>{kpi_html}</div>\"\n    if lat_html: html += f\"<h2>Latency</h2>{lat_html}\"\n    if ci_html:  html += ci_html\n    html += f\"<h2>Plots</h2><div class='grid'>{plots_html}</div>\"\n    if gradcam_html: html += f\"<h2>Grad-CAM Examples</h2><div class='grid'>{gradcam_html}</div>\"\n    html += \"</body></html>\"\n\n    with open(out_html, 'w') as f: f.write(html)\n    print(\"[ok] appendix ->\", out_html)\n\nbuild_html_appendix_fileonly()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T09:47:29.118309Z","iopub.execute_input":"2025-08-24T09:47:29.118679Z","iopub.status.idle":"2025-08-24T09:47:29.195044Z","shell.execute_reply.started":"2025-08-24T09:47:29.118652Z","shell.execute_reply":"2025-08-24T09:47:29.194284Z"}},"outputs":[{"name":"stdout","text":"[ok] appendix -> /kaggle/working/pcosgen_out/appendix.html\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# === Image-model metrics extractor (fills your comparison table) ===\nimport os, json, glob\n\nOUT = \"/kaggle/working/pcosgen_out\"  # change if needed\ndef _load(p):\n    try:\n        with open(p) as f: return json.load(f)\n    except Exception: return None\n\n# find latency file (fast preferred)\nlat = _load(os.path.join(OUT, \"latency_report_fast.json\")) or _load(os.path.join(OUT, \"latency_report.json\"))\nci  = _load(os.path.join(OUT, \"oof_metrics_ci.json\"))\nthr = _load(os.path.join(OUT, \"thresholds.json\"))\ncb  = _load(os.path.join(OUT, \"class_balance.json\"))\n\n# pull values (robust to missing)\ndef get_latency(lat, mode):\n    if not lat: return None\n    rows = [r for r in lat.get(\"results\", []) if r.get(\"mode\")==mode]\n    return rows[0] if rows else None\n\nr1  = get_latency(lat, \"no_TTA_bs1\")\nr8  = get_latency(lat, \"no_TTA_bs8\")\nr32 = get_latency(lat, \"no_TTA_bs32\")\n\nauc = ci.get(\"AUC_ROC\", {}).get(\"mean\") if ci else None\nap  = ci.get(\"AP\", {}).get(\"mean\") if ci else None\nbrier = ci.get(\"Brier\", {}).get(\"mean\") if ci else None\n\nthr_j   = thr.get(\"thr_j\") if thr else None\nthr_s80 = thr.get(\"thr_s80\") if thr else None\nthr_85  = thr.get(\"thr_85\") if thr else None\nm_85    = thr.get(\"m_85\") if thr else None  # contains F1 / Sens / Spec at the 85/85 target (or closest)\n\ndef fmt(x, digs=4):\n    return \"—\" if x is None else (f\"{x:.{digs}f}\" if isinstance(x,(int,float)) else str(x))\n\n# Build a compact “Image model” row you can paste into your paper table\nrow = {\n    \"AUC-ROC (OOF)\": fmt(auc),\n    \"AP (PR-AUC)\": fmt(ap),\n    \"Brier score\": fmt(brier),\n    \"F1 @ 85/85\": fmt(m_85.get(\"F1\") if m_85 else None, 4),\n    \"Sens @ 85/85\": fmt(m_85.get(\"RECALL_healthy\") if m_85 else None, 4),\n    \"Spec @ 85/85\": fmt(m_85.get(\"SPEC_unhealthy\") if m_85 else None, 4),\n    \"J* threshold\": fmt(thr_j, 3),\n    \"Spec80 threshold\": fmt(thr_s80, 3),\n    \"Latency ms/img (bs=1, no-TTA)\": fmt(r1.get(\"per_image_ms\") if r1 else None, 2),\n    \"Throughput (bs=8, no-TTA) img/s\": fmt(r8.get(\"throughput_img_per_s\") if r8 else None, 2),\n    \"Throughput (bs=32, no-TTA) img/s\": fmt(r32.get(\"throughput_img_per_s\") if r32 else None, 2),\n}\n\nprint(\"\\n=== Image model (paste into your table) ===\")\nfor k,v in row.items(): print(f\"{k}: {v}\")\n\n# Optional: show class balance\nif cb:\n    print(\"\\nClass balance:\", cb.get(\"counts\", {}), cb.get(\"percent\", {}))\nelse:\n    print(\"\\nClass balance: (file not found; optional)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T10:02:03.615639Z","iopub.execute_input":"2025-08-24T10:02:03.615905Z","iopub.status.idle":"2025-08-24T10:02:03.628180Z","shell.execute_reply.started":"2025-08-24T10:02:03.615886Z","shell.execute_reply":"2025-08-24T10:02:03.627610Z"}},"outputs":[{"name":"stdout","text":"\n=== Image model (paste into your table) ===\nAUC-ROC (OOF): 0.8141\nAP (PR-AUC): 0.6469\nBrier score: 0.1757\nF1 @ 85/85: 0.5980\nSens @ 85/85: 0.7752\nSpec @ 85/85: 0.6787\nJ* threshold: 0.463\nSpec80 threshold: 0.483\nLatency ms/img (bs=1, no-TTA): 31.96\nThroughput (bs=8, no-TTA) img/s: 121.43\nThroughput (bs=32, no-TTA) img/s: 167.42\n\nClass balance: {'0_unhealthy': 2297, '1_healthy': 903} {'0_unhealthy': 71.78125, '1_healthy': 28.218749999999996}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"%%bash\nif [ -d /kaggle/working/pcosgen_out ]; then\n  rm -f /kaggle/working/pcosgen_artifacts.zip\n  (cd /kaggle/working && zip -qr pcosgen_artifacts.zip pcosgen_out)\n  ls -lh /kaggle/working/pcosgen_artifacts.zip\nelse\n  echo \"Missing /kaggle/working/pcosgen_out\"\nfi\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T09:47:36.304968Z","iopub.execute_input":"2025-08-24T09:47:36.305240Z","iopub.status.idle":"2025-08-24T09:48:28.304703Z","shell.execute_reply.started":"2025-08-24T09:47:36.305220Z","shell.execute_reply":"2025-08-24T09:48:28.304045Z"}},"outputs":[{"name":"stdout","text":"-rw-r--r-- 1 root root 893M Aug 24 09:48 /kaggle/working/pcosgen_artifacts.zip\n","output_type":"stream"}],"execution_count":9}]}